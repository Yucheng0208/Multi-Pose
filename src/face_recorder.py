# face_recorder.py
# MediaPipe è‡‰éƒ¨ç¶²æ ¼æ¨¡å‹æª¢æ¸¬èˆ‡è¿½è¹¤è¨˜éŒ„å™¨
# æ”¯æ´ç›´æ¥åŸ·è¡Œèˆ‡æ¨¡çµ„ import ä½¿ç”¨

from __future__ import annotations
import argparse
import logging
from pathlib import Path
from typing import Iterable, Optional, List, Dict, Any, Tuple, Generator

import numpy as np
import pandas as pd
import cv2

try:
    import mediapipe as mp
except Exception as e:
    raise RuntimeError("MediaPipe is required. Please `pip install mediapipe`.") from e


# ---- MediaPipe Face Mesh Model å®šç¾© ----
# MediaPipe æä¾› 468 å€‹è‡‰éƒ¨ç¶²æ ¼é»ï¼Œé€™è£¡å®šç¾©å®Œæ•´çš„ç¶²æ ¼é»åç¨±
FACE_MESH_POINTS: List[str] = [
    # è‡‰éƒ¨è¼ªå»“ (0-16)
    "face_oval_0", "face_oval_1", "face_oval_2", "face_oval_3", "face_oval_4",
    "face_oval_5", "face_oval_6", "face_oval_7", "face_oval_8", "face_oval_9",
    "face_oval_10", "face_oval_11", "face_oval_12", "face_oval_13", "face_oval_14",
    "face_oval_15", "face_oval_16",
    
    # å³çœ¼ (33-46)
    "right_eye_0", "right_eye_1", "right_eye_2", "right_eye_3", "right_eye_4",
    "right_eye_5", "right_eye_6", "right_eye_7", "right_eye_8", "right_eye_9",
    "right_eye_10", "right_eye_11", "right_eye_12", "right_eye_13",
    
    # å·¦çœ¼ (362-375)
    "left_eye_0", "left_eye_1", "left_eye_2", "left_eye_3", "left_eye_4",
    "left_eye_5", "left_eye_6", "left_eye_7", "left_eye_8", "left_eye_9",
    "left_eye_10", "left_eye_11", "left_eye_12", "left_eye_13",
    
    # é¼»å­ (1, 2, 5, 31, 35, 195-207)
    "nose_tip", "nose_bottom", "nose_left", "nose_right", "nose_bridge",
    "nose_left_wing", "nose_right_wing", "nose_left_wing_tip", "nose_right_wing_tip",
    
    # å˜´å·´ (61-84, 85-108)
    "mouth_left", "mouth_right", "mouth_top", "mouth_bottom", "mouth_center",
    "upper_lip_top", "upper_lip_bottom", "lower_lip_top", "lower_lip_bottom",
    
    # çœ‰æ¯› (70-76, 336-342)
    "right_eyebrow_0", "right_eyebrow_1", "right_eyebrow_2", "right_eyebrow_3",
    "right_eyebrow_4", "right_eyebrow_5", "right_eyebrow_6",
    "left_eyebrow_0", "left_eyebrow_1", "left_eyebrow_2", "left_eyebrow_3",
    "left_eyebrow_4", "left_eyebrow_5", "left_eyebrow_6"
]

# ç°¡åŒ–ç‰ˆæœ¬ï¼šåªä½¿ç”¨æœ€é‡è¦çš„ç¶²æ ¼é»ï¼ˆ16å€‹ï¼‰
SIMPLE_FACE_MESH_POINTS: List[str] = [
    "nose_tip", "nose_bottom", "nose_left", "nose_right",
    "right_eye_center", "left_eye_center",
    "mouth_left", "mouth_right", "mouth_top", "mouth_bottom",
    "right_eyebrow_center", "left_eyebrow_center",
    "face_oval_top", "face_oval_bottom", "face_oval_left", "face_oval_right"
]

# å®Œæ•´ 468 é»ç¶²æ ¼é»åç¨±ï¼ˆåŸºæ–¼ MediaPipe å®˜æ–¹å®šç¾©ï¼‰
FULL_FACE_MESH_POINTS: List[str] = [
    # è‡‰éƒ¨è¼ªå»“ (0-16)
    "face_oval_0", "face_oval_1", "face_oval_2", "face_oval_3", "face_oval_4",
    "face_oval_5", "face_oval_6", "face_oval_7", "face_oval_8", "face_oval_9",
    "face_oval_10", "face_oval_11", "face_oval_12", "face_oval_13", "face_oval_14",
    "face_oval_15", "face_oval_16",
    
    # å³çœ¼ (33-46)
    "right_eye_0", "right_eye_1", "right_eye_2", "right_eye_3", "right_eye_4",
    "right_eye_5", "right_eye_6", "right_eye_7", "right_eye_8", "right_eye_9",
    "right_eye_10", "right_eye_11", "right_eye_12", "right_eye_13",
    
    # å·¦çœ¼ (362-375)
    "left_eye_0", "left_eye_1", "left_eye_2", "left_eye_3", "left_eye_4",
    "left_eye_5", "left_eye_6", "left_eye_7", "left_eye_8", "left_eye_9",
    "left_eye_10", "left_eye_11", "left_eye_12", "left_eye_13",
    
    # é¼»å­ (1, 2, 5, 31, 35, 195-207)
    "nose_tip", "nose_bottom", "nose_left", "nose_right", "nose_bridge",
    "nose_left_wing", "nose_right_wing", "nose_left_wing_tip", "nose_right_wing_tip",
    
    # å˜´å·´ (61-84, 85-108)
    "mouth_left", "mouth_right", "mouth_top", "mouth_bottom", "mouth_center",
    "upper_lip_top", "upper_lip_bottom", "lower_lip_top", "lower_lip_bottom",
    
    # çœ‰æ¯› (70-76, 336-342)
    "right_eyebrow_0", "right_eyebrow_1", "right_eyebrow_2", "right_eyebrow_3",
    "right_eyebrow_4", "right_eyebrow_5", "right_eyebrow_6",
    "left_eyebrow_0", "left_eyebrow_1", "left_eyebrow_2", "left_eyebrow_3",
    "left_eyebrow_4", "left_eyebrow_5", "left_eyebrow_6"
]

# ç¶²æ ¼é»ç´¢å¼•æ˜ å°„ï¼ˆMediaPipe 468 é»ä¸­çš„ç´¢å¼•ï¼‰
MESH_POINT_INDICES = {
    "nose_tip": 1,
    "nose_bottom": 2,
    "nose_left": 5,
    "nose_right": 31,
    "right_eye_center": 159,
    "left_eye_center": 386,
    "mouth_left": 61,
    "mouth_right": 291,
    "mouth_top": 13,
    "mouth_bottom": 14,
    "right_eyebrow_center": 70,
    "left_eyebrow_center": 336,
    "face_oval_top": 10,
    "face_oval_bottom": 152,
    "face_oval_left": 234,
    "face_oval_right": 454
}

# å®Œæ•´çš„ 468 é»ç´¢å¼•æ˜ å°„ï¼ˆé€™è£¡åªåˆ—å‡ºéƒ¨åˆ†ï¼Œå¯¦éš›æ‡‰è©²æœ‰ 468 å€‹ï¼‰
# ç‚ºäº†ç°¡åŒ–ï¼Œæˆ‘å€‘å°‡ä½¿ç”¨ MediaPipe çš„åŸå§‹ç´¢å¼• 0-467
FULL_MESH_INDICES = {f"point_{i}": i for i in range(468)}


def _ensure_dir(p: Path) -> None:
    """ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨"""
    p.parent.mkdir(parents=True, exist_ok=True)


class FaceMeshRecorder:
    """
    è¨˜éŒ„æ¯å¹€ã€æ¯å€‹è‡‰éƒ¨ã€æ¯å€‹ç¶²æ ¼é»çš„è³‡æ–™åˆ—ï¼š
    <id><keypoints><model><coor_x><coor_y><cm>
    æ”¯æ´å®Œæ•´çš„ 468 é» MediaPipe Face Mesh
    """

    def __init__(
        self,
        use_simple_mesh_points: bool = True,
        use_full_mesh: bool = False,
        device: Optional[str] = None,
        conf: float = 0.5,
        max_faces: int = 1,
        pixel_to_cm: Optional[float] = None,
        kp_score_min: float = 0.0,
        model_label: str = "mediapipe_face_mesh",
        window_width: int = 640,
        window_height: int = 480,
    ) -> None:
        self.use_simple_mesh_points = use_simple_mesh_points
        self.use_full_mesh = use_full_mesh
        self.device = device
        self.conf = conf
        self.max_faces = max_faces
        self.pixel_to_cm = pixel_to_cm
        self.kp_score_min = kp_score_min
        self.model_label = model_label
        self.window_width = window_width
        self.window_height = window_height

        # åˆå§‹åŒ– MediaPipe Face Mesh
        self.mp_face_mesh = mp.solutions.face_mesh
        self.mp_drawing = mp.solutions.drawing_utils
        self.mp_drawing_styles = mp.solutions.drawing_styles
        
        # è¨­å®šè‡‰éƒ¨ç¶²æ ¼æª¢æ¸¬åƒæ•¸
        self.face_mesh = self.mp_face_mesh.FaceMesh(
            static_image_mode=False,
            max_num_faces=self.max_faces,
            refine_landmarks=True,
            min_detection_confidence=self.conf,
            min_tracking_confidence=self.conf
        )
        
        # é¸æ“‡ä½¿ç”¨çš„ç¶²æ ¼é»åˆ—è¡¨
        if use_full_mesh:
            self.mesh_points = list(range(468))  # ä½¿ç”¨æ‰€æœ‰ 468 é»
            self.mesh_point_names = [f"point_{i}" for i in range(468)]
        elif use_simple_mesh_points:
            self.mesh_points = SIMPLE_FACE_MESH_POINTS
            self.mesh_point_names = SIMPLE_FACE_MESH_POINTS
        else:
            self.mesh_points = FACE_MESH_POINTS
            self.mesh_point_names = FACE_MESH_POINTS
        
        logging.info("å·²åˆå§‹åŒ– MediaPipe Face Mesh æ¨¡å‹: %s", self.model_label)
        logging.info("ä½¿ç”¨ %d å€‹ç¶²æ ¼é»", len(self.mesh_points))
        logging.info("è¦–çª—å°ºå¯¸: %dx%d", self.window_width, self.window_height)

    def _detect_faces(self, frame: np.ndarray) -> List[Dict[str, Any]]:
        """
        æª¢æ¸¬å–®ä¸€å½±åƒä¸­çš„è‡‰éƒ¨ç¶²æ ¼é»
        """
        # è½‰æ›ç‚º RGBï¼ˆMediaPipe éœ€è¦ RGB æ ¼å¼ï¼‰
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        
        # é€²è¡Œè‡‰éƒ¨ç¶²æ ¼æª¢æ¸¬
        results = self.face_mesh.process(rgb_frame)
        
        faces = []
        if results.multi_face_landmarks:
            for face_landmarks in results.multi_face_landmarks:
                face_data = {
                    'landmarks': face_landmarks,
                    'mesh_points': {}
                }
                
                # æå–ç¶²æ ¼é»åº§æ¨™
                if self.use_full_mesh:
                    # ä½¿ç”¨æ‰€æœ‰ 468 é»
                    for i in range(468):
                        if i < len(face_landmarks.landmark):
                            landmark = face_landmarks.landmark[i]
                            h, w = frame.shape[:2]
                            x = int(landmark.x * w)
                            y = int(landmark.y * h)
                            z = landmark.z  # æ·±åº¦å€¼ï¼ˆç›¸å°ï¼‰
                            face_data['mesh_points'][f"point_{i}"] = (x, y, z)
                elif self.use_simple_mesh_points:
                    # ä½¿ç”¨ç°¡åŒ–ç¶²æ ¼é»é›†
                    for mesh_point_name in SIMPLE_FACE_MESH_POINTS:
                        if mesh_point_name in MESH_POINT_INDICES:
                            idx = MESH_POINT_INDICES[mesh_point_name]
                            if idx < len(face_landmarks.landmark):
                                landmark = face_landmarks.landmark[idx]
                                h, w = frame.shape[:2]
                                x = int(landmark.x * w)
                                y = int(landmark.y * h)
                                z = landmark.z  # æ·±åº¦å€¼ï¼ˆç›¸å°ï¼‰
                                face_data['mesh_points'][mesh_point_name] = (x, y, z)
                else:
                    # ä½¿ç”¨è‡ªè¨‚ç¶²æ ¼é»é›†
                    for mesh_point_name in FACE_MESH_POINTS:
                        if mesh_point_name in MESH_POINT_INDICES:
                            idx = MESH_POINT_INDICES[mesh_point_name]
                            if idx < len(face_landmarks.landmark):
                                landmark = face_landmarks.landmark[idx]
                                h, w = frame.shape[:2]
                                x = int(landmark.x * w)
                                y = int(landmark.y * h)
                                z = landmark.z  # æ·±åº¦å€¼ï¼ˆç›¸å°ï¼‰
                                face_data['mesh_points'][mesh_point_name] = (x, y, z)
                
                faces.append(face_data)
        
        return faces

    def _rows_from_frame(self, frame: np.ndarray, frame_id: int = 0) -> List[Dict[str, Any]]:
        """
        å°‡ä¸€å¹€çš„æª¢æ¸¬çµæœè½‰æ›ç‚ºçµ±ä¸€çš„é—œéµé»æ ¼å¼
        """
        rows: List[Dict[str, Any]] = []
        
        # æª¢æ¸¬è‡‰éƒ¨ç¶²æ ¼
        faces = self._detect_faces(frame)
        
        for face_idx, face_data in enumerate(faces):
            face_id = frame_id * 1000 + face_idx  # ç°¡å–®çš„ ID åˆ†é…
            landmarks = {}
            
            for mesh_point_name, (x, y, z) in face_data['mesh_points'].items():
                # æª¢æŸ¥åº§æ¨™æœ‰æ•ˆæ€§
                if np.isnan(x) or np.isnan(y):
                    continue
                
                # ä½¿ç”¨ z å€¼ä½œç‚º confidenceï¼ˆMediaPipe çš„ z å€¼ç¯„åœé€šå¸¸åœ¨ -1 åˆ° 1 ä¹‹é–“ï¼‰
                confidence = max(0.0, min(1.0, (z + 1.0) / 2.0))  # è½‰æ›åˆ° 0-1 ç¯„åœ
                
                landmarks[mesh_point_name] = {
                    "x": float(x),
                    "y": float(y),
                    "confidence": confidence
                }
            
            if landmarks:  # åªæ·»åŠ æœ‰æœ‰æ•ˆé—œéµé»çš„çµæœ
                rows.append({
                    "id": face_id,
                    "landmarks": landmarks,
                    "model": self.model_label
                })
        
        return rows

    def process_source(
        self,
        source: Any,
        output_path: Optional[str] = "face_mesh_records.csv",
        video_out_path: Optional[str] = None,
        visualize: bool = False,
        save_fps: Optional[float] = None,
        window_name: Optional[str] = None,
    ) -> None:
        """
        è™•ç†å½±åƒä¾†æºä¸¦è¼¸å‡ºè‡‰éƒ¨ç¶²æ ¼é»è³‡æ–™
        """
        writer = None
        video_writer = None
        out_is_parquet = bool(output_path and str(output_path).lower().endswith(".parquet"))
        accum: List[Tuple[int, str, str, float, float, Any]] = []
        
        vc_fps = None
        frame_count = 0
        
        # è¨­å®šè¦–çª—åç¨±
        if window_name is None:
            window_name = "face_mesh_recorder"
        
        try:
            # é–‹å•Ÿå½±åƒä¾†æº
            if isinstance(source, (str, int)):
                cap = cv2.VideoCapture(source)
                if not cap.isOpened():
                    raise RuntimeError(f"ç„¡æ³•é–‹å•Ÿå½±åƒä¾†æº: {source}")
                
                # è¨­å®šæ”å½±æ©Ÿè§£æåº¦ç‚º 1920x1080ï¼ˆå¦‚æœæ˜¯ç¶²è·¯æ”å½±æ©Ÿï¼‰
                if source == 0 or source == "0":
                    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)
                    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)
                    
                    # é©—è­‰è§£æåº¦è¨­å®š
                    actual_width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)
                    actual_height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)
                    logging.info(f"ğŸ“¹ æ”å½±æ©Ÿè§£æåº¦: {actual_width:.0f}x{actual_height:.0f}")
            else:
                cap = source
            
            # å–å¾— FPS
            if save_fps is None:
                vc_fps = cap.get(cv2.CAP_PROP_FPS) or 30.0
            else:
                vc_fps = float(save_fps)
            
            # è¨­å®šè¦–çª—å°ºå¯¸
            if visualize:
                cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
                cv2.resizeWindow(window_name, self.window_width, self.window_height)
            
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # è™•ç†ç•¶å‰å¹€
                rows = self._rows_from_frame(frame, frame_count)
                accum.extend(rows)
                
                # ç¹ªè£½æª¢æ¸¬çµæœï¼ˆå¦‚æœéœ€è¦ï¼‰
                if (visualize or video_out_path) and frame is not None:
                    # åœ¨åŸå§‹å½±åƒä¸Šç¹ªè£½è‡‰éƒ¨ç¶²æ ¼é»
                    drawn_frame = self._draw_face_mesh_points(frame, rows)
                    
                    if visualize:
                        cv2.imshow(window_name, drawn_frame)
                        if cv2.waitKey(1) & 0xFF == 27:  # ESC
                            break
                    
                    if video_out_path:
                        if video_writer is None:
                            h, w = drawn_frame.shape[:2]
                            _ensure_dir(Path(video_out_path))
                            fourcc = cv2.VideoWriter_fourcc(*"mp4v")
                            video_writer = cv2.VideoWriter(str(video_out_path), fourcc, vc_fps, (w, h))
                        video_writer.write(drawn_frame)
                
                frame_count += 1
                
                # æ¯ 100 å¹€è¼¸å‡ºé€²åº¦
                if frame_count % 100 == 0:
                    logging.info("å·²è™•ç† %d å¹€ï¼Œæª¢æ¸¬åˆ° %d å€‹ç¶²æ ¼é»", frame_count, len(accum))
            
            # é—œé–‰å½±åƒä¾†æº
            if isinstance(source, (str, int)):
                cap.release()
            
            # è¼¸å‡ºè³‡æ–™
            if output_path:
                _ensure_dir(Path(output_path))
                df = pd.DataFrame(accum, columns=["id", "keypoints", "model", "coor_x", "coor_y", "cm"])
                if out_is_parquet:
                    df.to_parquet(output_path, index=False)
                else:
                    df.to_csv(output_path, index=False)
                logging.info("å·²å„²å­˜è‡‰éƒ¨ç¶²æ ¼é»è¨˜éŒ„åˆ° %s (%d åˆ—)", output_path, len(df))
        
        finally:
            if video_writer is not None:
                video_writer.release()
            if visualize:
                cv2.destroyAllWindows()

    def _draw_face_mesh_points(self, frame: np.ndarray, rows: List[Tuple[int, str, str, float, float, Any]]) -> np.ndarray:
        """
        åœ¨å½±åƒä¸Šç¹ªè£½è‡‰éƒ¨ç¶²æ ¼é»
        """
        drawn_frame = frame.copy()
        
        # æŒ‰è‡‰éƒ¨ ID åˆ†çµ„ç¶²æ ¼é»
        face_mesh_points = {}
        for row in rows:
            face_id, mesh_point_name, _, x, y, _ = row
            if face_id not in face_mesh_points:
                face_mesh_points[face_id] = []
            face_mesh_points[face_id].append((mesh_point_name, int(x), int(y)))
        
        # ç‚ºæ¯å€‹è‡‰éƒ¨ç¹ªè£½ç¶²æ ¼é»
        for face_id, mesh_points in face_mesh_points.items():
            # ç¹ªè£½ç¶²æ ¼é»
            for mesh_point_name, x, y in mesh_points:
                # æ ¹æ“šç¶²æ ¼é»é¡å‹ä½¿ç”¨ä¸åŒé¡è‰²
                if "eye" in mesh_point_name:
                    color = (0, 255, 0)  # ç¶ è‰²çœ¼ç›
                elif "nose" in mesh_point_name:
                    color = (255, 0, 0)  # è—è‰²é¼»å­
                elif "mouth" in mesh_point_name:
                    color = (0, 0, 255)  # ç´…è‰²å˜´å·´
                elif "eyebrow" in mesh_point_name:
                    color = (255, 255, 0)  # é’è‰²çœ‰æ¯›
                elif "face_oval" in mesh_point_name:
                    color = (255, 0, 255)  # æ´‹ç´…è‰²è‡‰éƒ¨è¼ªå»“
                else:
                    color = (128, 128, 128)  # ç°è‰²å…¶ä»–é»
                
                cv2.circle(drawn_frame, (x, y), 2, color, -1)
                
                # åªç‚ºé‡è¦é»é¡¯ç¤ºåç¨±ï¼ˆé¿å…éæ–¼æ“æ“ ï¼‰
                if not self.use_full_mesh or "point_" not in mesh_point_name:
                    cv2.putText(drawn_frame, mesh_point_name, (x+3, y-3), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.3, (255, 255, 255), 1)
            
            # ç¹ªè£½è‡‰éƒ¨ ID
            if mesh_points:
                x, y = mesh_points[0][1], mesh_points[0][2]
                cv2.putText(drawn_frame, f"Face {face_id}", (x, y-20), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)
        
        return drawn_frame

    def process_image(self, image_path: str, output_path: Optional[str] = None) -> List[Tuple[int, str, str, float, float, Any]]:
        """
        è™•ç†å–®ä¸€å½±åƒæª”æ¡ˆ
        """
        frame = cv2.imread(image_path)
        if frame is None:
            raise RuntimeError(f"ç„¡æ³•è®€å–å½±åƒ: {image_path}")
        
        rows = self._rows_from_frame(frame, 0)
        
        if output_path:
            _ensure_dir(Path(output_path))
            df = pd.DataFrame(rows, columns=["id", "keypoints", "model", "coor_x", "coor_y", "cm"])
            if output_path.lower().endswith(".parquet"):
                df.to_parquet(output_path, index=False)
            else:
                df.to_csv(output_path, index=False)
            logging.info("å·²å„²å­˜è‡‰éƒ¨ç¶²æ ¼é»è¨˜éŒ„åˆ° %s (%d åˆ—)", output_path, len(df))
        
        return rows

    def get_mesh_statistics(self) -> Dict[str, Any]:
        """
        ç²å–ç¶²æ ¼é»çµ±è¨ˆè³‡è¨Š
        """
        return {
            "total_points": len(self.mesh_points),
            "use_full_mesh": self.use_full_mesh,
            "use_simple_mesh": self.use_simple_mesh_points,
            "mesh_point_names": self.mesh_point_names,
            "model_label": self.model_label
        }
    
    def close(self):
        """
        é—œé–‰è³‡æºä¸¦æ¸…ç†
        """
        if hasattr(self, 'face_mesh'):
            self.face_mesh.close()
        logging.info("FaceMeshRecorder å·²é—œé–‰")


def run_inference(
    source: Any,
    output: str = "face_mesh_records.csv",
    use_simple_mesh_points: bool = True,
    use_full_mesh: bool = False,
    device: Optional[str] = None,
    conf: float = 0.5,
    max_faces: int = 1,
    pixel_to_cm: Optional[float] = None,
    kp_score_min: float = 0.0,
    video_out: Optional[str] = None,
    visualize: bool = False,
    save_fps: Optional[float] = None,
    window_width: int = 640,
    window_height: int = 480,
    window_name: Optional[str] = None,
) -> None:
    """
    ä¾¿åˆ©å‡½å¼ï¼šåŸ·è¡Œè‡‰éƒ¨ç¶²æ ¼é»æª¢æ¸¬
    """
    rec = FaceMeshRecorder(
        use_simple_mesh_points=use_simple_mesh_points,
        use_full_mesh=use_full_mesh,
        device=device,
        conf=conf,
        max_faces=max_faces,
        pixel_to_cm=pixel_to_cm,
        kp_score_min=kp_score_min,
        window_width=window_width,
        window_height=window_height,
    )
    
    rec.process_source(
        source=source,
        output_path=output,
        video_out_path=video_out,
        visualize=visualize,
        save_fps=save_fps,
        window_name=window_name,
    )


def _build_parser() -> argparse.ArgumentParser:
    """å»ºç«‹å‘½ä»¤åˆ—åƒæ•¸è§£æå™¨"""
    p = argparse.ArgumentParser(description="MediaPipe è‡‰éƒ¨ç¶²æ ¼é»æª¢æ¸¬è¨˜éŒ„å™¨")
    p.add_argument("--source", type=str, default="0", help="0 ç‚ºç¶²è·¯æ”å½±æ©Ÿï¼Œæˆ–å½±åƒ/å½±ç‰‡è·¯å¾‘")
    p.add_argument("--output", type=str, default="face_mesh_records.csv", help="è¼¸å‡ºæª”æ¡ˆè·¯å¾‘")
    p.add_argument("--use-simple-mesh-points", action="store_true", default=True, help="ä½¿ç”¨ç°¡åŒ–ç¶²æ ¼é»é›†ï¼ˆ16é»ï¼‰")
    p.add_argument("--use-full-mesh", action="store_true", help="ä½¿ç”¨å®Œæ•´ 468 é»ç¶²æ ¼")
    p.add_argument("--device", type=str, default=None, help="é‹ç®—è£ç½®")
    p.add_argument("--conf", type=float, default=0.5, help="æª¢æ¸¬ä¿¡å¿ƒé–¾å€¼")
    p.add_argument("--max-faces", type=int, default=1, help="æœ€å¤§æª¢æ¸¬è‡‰éƒ¨æ•¸é‡")
    p.add_argument("--pixel-to-cm", type=float, default=None, help="åƒç´ è½‰å…¬åˆ†æ¯”ä¾‹")
    p.add_argument("--kp-score-min", type=float, default=0.0, help="ç¶²æ ¼é»æœ€å°åˆ†æ•¸")
    p.add_argument("--video-out", type=str, default=None, help="è¼¸å‡ºå½±ç‰‡è·¯å¾‘")
    p.add_argument("--visualize", action="store_true", help="é¡¯ç¤ºè¦–çª—")
    p.add_argument("--save-fps", type=float, default=None, help="å„²å­˜å½±ç‰‡ FPS")
    p.add_argument("--window-width", type=int, default=1080, help="è¦–çª—å¯¬åº¦ï¼ˆé è¨­ï¼š1080ï¼‰")
    p.add_argument("--window-height", type=int, default=1920, help="è¦–çª—é«˜åº¦ï¼ˆé è¨­ï¼š1920ï¼‰")
    p.add_argument("--window-name", type=str, default="Face Mesh Detection", help="è¦–çª—åç¨±")
    p.add_argument("--loglevel", type=str, default="INFO", help="æ—¥èªŒç­‰ç´š")
    return p


def main() -> None:
    """ä¸»ç¨‹å¼å…¥å£é»"""
    args = _build_parser().parse_args()
    
    # è¨­å®šæ—¥èªŒ
    logging.basicConfig(
        level=getattr(logging, str(args.loglevel).upper(), logging.INFO),
        format="%(asctime)s | %(levelname)s | %(message)s",
    )
    
    # è™•ç†ä¾†æºåƒæ•¸
    source: Any
    if args.source.isdigit():
        source = int(args.source)
    else:
        source = args.source
    
    # åŸ·è¡Œæª¢æ¸¬
    run_inference(
        source=source,
        output=args.output,
        use_simple_mesh_points=args.use_simple_mesh_points,
        use_full_mesh=args.use_full_mesh,
        device=args.device,
        conf=args.conf,
        max_faces=args.max_faces,
        pixel_to_cm=args.pixel_to_cm,
        kp_score_min=args.kp_score_min,
        video_out=args.video_out,
        visualize=args.visualize,
        save_fps=args.save_fps,
        window_width=args.window_width,
        window_height=args.window_height,
        window_name=args.window_name,
    )


if __name__ == "__main__":
    main()
