# Multi-Pose: A Mesh-Structured Network of Keypoints for Landmark Detection
*(å¤šæ¨¡æ…‹å§¿æ…‹ï¼šç”¨æ–¼ç‰¹å¾µé»åµæ¸¬çš„ç¶²æ ¼çµæ§‹åŒ–é—œéµé»ç¶²çµ¡)*

![Demo GIF](https_github_com_polite-AI_Real-time-Sign-Language-to-Speech-Conversion/assets/95745582/d0ba326b-d3a9-467f-94a2-97210986716d)
*(å»ºè­°ï¼šè«‹å°‡ä¸Šæ–¹é€£çµæ›¿æ›ç‚ºæ‚¨è‡ªå·±éŒ„è£½çš„å°ˆæ¡ˆå±•ç¤º GIF æˆ–åœ–ç‰‡)*

**Multi-Pose** æ˜¯ä¸€å€‹é«˜æ•ˆèƒ½ã€å³æ™‚çš„æ¡†æ¶ï¼Œå°ˆç‚ºæ•æ‰äººé«”å…¨é¢çš„å‹•æ…‹ç‰¹å¾µé»è€Œè¨­è¨ˆã€‚æœ¬æ¡†æ¶çš„æ ¸å¿ƒæ€æƒ³æ˜¯èåˆä¸åŒæ¨¡å‹çš„å„ªå‹¢â€”â€”çµåˆ **YOLOv8-Pose** çš„å¿«é€Ÿå…¨èº«å§¿æ…‹ä¼°è¨ˆèˆ‡ **Google MediaPipe** çš„é«˜ç²¾åº¦æ‰‹éƒ¨åŠè‡‰éƒ¨ç´°ç¯€â€”â€”å¾è€Œç‚ºå–®ä¸€äººç‰©ç”Ÿæˆä¸€å€‹çµ±ä¸€çš„ã€ç¶²æ ¼çµæ§‹åŒ–çš„ **537å€‹ç‰¹å¾µé»ï¼ˆLandmarksï¼‰** ç¶²çµ¡ã€‚

é€™å€‹ç³»çµ±ä¸åƒ…åƒ…æ˜¯ä¸€å€‹åµæ¸¬å·¥å…·ï¼Œå®ƒæ›´æ˜¯ä¸€å€‹å¼·å¤§çš„æ•¸æ“šæ¡é›†å¼•æ“ï¼Œç‚ºæ‰‹èªè¾¨è­˜ (SLR)ã€è™›æ“¬åŒ–èº«æ§åˆ¶ (Avatar Control)ã€æƒ…æ„Ÿåˆ†æ (Emotion Analysis) å’Œé€²éšäººæ©Ÿäº’å‹• (HCI) ç­‰æ‡‰ç”¨æä¾›äº†æ¥µå…¶è±å¯Œã€çµæ§‹åŒ–çš„æ•¸æ“šä¾†æºã€‚

## âœ¨ æ ¸å¿ƒåŠŸèƒ½ (Core Features)

-   **ğŸš€ å³æ™‚é«˜æ•ˆèƒ½ (Real-Time High Performance)**ï¼šåœ¨ GPU åŠ é€Ÿä¸‹å¯¦ç¾æµæš¢çš„å³æ™‚åµæ¸¬ï¼Œä¸¦èƒ½ç²¾ç¢ºè¨ˆç®—èˆ‡é¡¯ç¤ºçœŸå¯¦çš„è™•ç†å¹€ç‡ (Real FPS)ï¼Œä»¥è©•ä¼°ç³»çµ±æ€§èƒ½ã€‚
-   **ğŸ§© æ··åˆæ¨¡å‹æ¶æ§‹ (Hybrid Model Architecture)**ï¼š
    -   **å…¨èº«å§¿æ…‹ (Full Body)**: ä½¿ç”¨ `YOLOv8-Pose` é€²è¡Œå¿«é€Ÿä¸”ç©©å¥çš„äººé«”åµæ¸¬èˆ‡17å€‹ä¸»è¦é—œç¯€é»å®šä½ã€‚
    -   **ç²¾ç´°æ‰‹éƒ¨ (High-Fidelity Hands)**: ä½¿ç”¨ `MediaPipe Hands` åœ¨å…¨ç•«å¹…ä¸Šå°é›™æ‰‹é€²è¡Œåµæ¸¬ï¼Œæ•æ‰æ¯éš»æ‰‹21å€‹ç´°å¾®çš„æŒ‡é—œç¯€é»ã€‚
    -   **å¯†é›†è‡‰éƒ¨ (Dense Face Mesh)**: ä½¿ç”¨ `MediaPipe Face Mesh` åœ¨ YOLO å®šä½çš„è‡‰éƒ¨å€åŸŸå…§ï¼Œç”Ÿæˆé«˜é”478å€‹ç‰¹å¾µé»çš„å¯†é›†ç¶²æ ¼ï¼Œç²¾æº–æ•æ‰è¡¨æƒ…ç´°ç¯€ã€‚
-   **ğŸ“Š å…¨é¢çš„ç‰¹å¾µé»è¦†è“‹ (Comprehensive Landmark Coverage - 537 Points)**ï¼š
    -   **èº«é«”å§¿æ…‹ (Pose)**: 17 å€‹ç‰¹å¾µé»
    -   **é›™æ‰‹ (Hands)**: 42 å€‹ç‰¹å¾µé» (21 å·¦ + 21 å³)
    -   **è‡‰éƒ¨ç¶²æ ¼ (Face Mesh)**: 478 å€‹ç‰¹å¾µé»
-   **ğŸ’¾ çµæ§‹åŒ– JSON è¼¸å‡º (Structured JSON Output)**ï¼š
    -   ç‚ºå½±ç‰‡çš„æ¯ä¸€å¹€ç”Ÿæˆä¸€å€‹ç¨ç«‹ã€åºåˆ—ç·¨è™Ÿçš„ JSON æª”æ¡ˆ (e.g., `000000000001.json`)ã€‚
    -   æ•¸æ“šæ ¼å¼æ¸…æ™°ï¼Œè©³ç´°è¨˜éŒ„äº†å¹€IDã€åµæ¸¬äººæ•¸ã€äººç‰©IDï¼Œä»¥åŠèº«é«”ã€é›™æ‰‹ã€è‡‰éƒ¨æ‰€æœ‰ç‰¹å¾µé»çš„ç´¢å¼•ã€`x, y` åº§æ¨™èˆ‡ä¿¡å¿ƒåº¦ã€‚
-   **ğŸ–¥ï¸ è³‡è¨Šè±å¯Œçš„è¦–è¦ºåŒ–ä»‹é¢ (Informative Visualization)**ï¼š
    -   å³æ™‚æ¸²æŸ“æ‰€æœ‰æ¨¡å‹çš„åµæ¸¬çµæœï¼ŒåŒ…æ‹¬éª¨æ¶é€£ç·šã€æ‰‹éƒ¨é—œç¯€å’Œè‡‰éƒ¨ç¶²æ ¼ã€‚
    -   å‹•æ…‹é¡¯ç¤ºçœŸå¯¦FPSã€å„æ¨¡çµ„åµæ¸¬ç‹€æ…‹ (OK/X)ã€ç¸½äººæ•¸ç­‰é—œéµè³‡è¨Šã€‚

## ğŸ› ï¸ æŠ€è¡“å †ç–Š (Tech Stack)

-   **Pose Estimation**: [Ultralytics YOLOv8-Pose](https://github.com/ultralytics/ultralytics)
-   **Hand & Face Landmarks**: [Google MediaPipe](https://developers.google.com/mediapipe)
-   **Core Framework**: PyTorch
-   **Image Processing**: OpenCV
-   **Numerical Computing**: NumPy

## âš™ï¸ ç’°å¢ƒè¨­å®šèˆ‡å®‰è£ (Setup and Installation)

### 1. å‰ç½®éœ€æ±‚
-   Python 3.8+
-   **å¼·çƒˆå»ºè­°**: NVIDIA GPU with CUDA & cuDNN for real-time performance.

### 2. è¤‡è£½æ­¤å„²å­˜åº«
```bash
git clone [æ‚¨çš„GitHubå„²å­˜åº«é€£çµ]
cd Multi-Pose
```

### 3. å»ºç«‹ä¸¦å•Ÿç”¨ Python è™›æ“¬ç’°å¢ƒ
```bash
# Windows
python -m venv venv
.\venv\Scripts\activate

# macOS / Linux
python3 -m venv venv
source venv/bin/activate
```

### 4. å®‰è£ä¾è³´å¥—ä»¶
```bash
pip install -r requirements.txt
```
è‹¥ç„¡ `requirements.txt`ï¼Œè«‹æ‰‹å‹•å®‰è£ï¼š
```bash
pip install ultralytics mediapipe opencv-python torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```
*(è«‹æ ¹æ“šæ‚¨çš„ CUDA ç‰ˆæœ¬é¸æ“‡å°æ‡‰çš„ PyTorch æŒ‡ä»¤)*

### 5. ä¸‹è¼‰é è¨“ç·´æ¨¡å‹
åœ¨å°ˆæ¡ˆæ ¹ç›®éŒ„ä¸‹å»ºç«‹ `models` è³‡æ–™å¤¾ï¼Œä¸¦ä¸‹è¼‰ä»¥ä¸‹æ¨¡å‹æª”æ¡ˆæ”¾å…¥å…¶ä¸­ã€‚

```
Multi-Pose/
â””â”€â”€ models/
    â”œâ”€â”€ yolo11n-pose.pt       # YOLOv8-Pose model
    â”œâ”€â”€ hand_landmarker.task  # MediaPipe Hands model
    â””â”€â”€ face_landmarker.task  # MediaPipe Face Mesh model
```
-   YOLO Models: [Ultralytics GitHub Releases](https://github.com/ultralytics/assets/releases)
-   MediaPipe Task Models: [MediaPipe for Python Models Page](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/python#models)

## ğŸš€ é‹è¡Œç³»çµ± (Running the System)

é€é `main.py` å•Ÿå‹•ã€‚ç›®å‰ä¸»è¦æ”¯æ´å³æ™‚é¡é ­æ¨¡å¼ã€‚

### Real-Time Webcam Mode
æ­¤æ¨¡å¼å°‡å•Ÿå‹•é è¨­æ”å½±æ©Ÿï¼Œä¸¦å°‡çµæ§‹åŒ–çš„ JSON æ•¸æ“šå³æ™‚å„²å­˜è‡³ `output_json/`ã€‚
```bash
python main.py --mode realtime
```
-   æŒ‡å®šä¸åŒçš„æ”å½±æ©Ÿ:
    ```bash
    python main.py --mode realtime --camera 1
    ```
-   ä½¿ç”¨ CPU é‹è¡Œ (æ•ˆèƒ½å°‡é¡¯è‘—é™ä½):
    ```bash
    python main.py --device cpu
    ```

## ğŸ“¦ è¼¸å‡º JSON æ•¸æ“šçµæ§‹ (Output JSON Data Structure)

æ¯ä¸€å¹€éƒ½æœƒç”Ÿæˆä¸€å€‹ JSON æª”æ¡ˆï¼Œå…¶æ•¸æ“šçµæ§‹è¨­è¨ˆæ¸…æ™°ï¼Œä¾¿æ–¼è§£æèˆ‡ä½¿ç”¨ã€‚

```json
{
    "frame_id": 123,
    "num_persons": 1,
    "persons": [
        {
            "person_id": 0,
            "keypoints": {
                "pose": [
                    { "id": 0, "x": 640.5, "y": 320.1, "confidence": 0.95 },
                    ... 16 more ...
                ],
                "left_hand": [
                    { "id": 0, "x": 410.2, "y": 450.7, "confidence": 0.99 },
                    ... 20 more ...
                ],
                "right_hand": [
                    { "id": 0, "x": 810.2, "y": 450.7, "confidence": 0.99 },
                    ... 20 more ...
                ],
                "face": [
                    { "id": 0, "x": 630.1, "y": 280.6, "confidence": 1.0 },
                    ... 477 more ...
                ]
            }
        }
    ]
}
```
-   **`frame_id`**: å¹€çš„åºåˆ—è™Ÿã€‚
-   **`num_persons`**: ç•«é¢ä¸­åµæ¸¬åˆ°çš„ç¸½äººæ•¸ã€‚
-   **`persons`**: åŒ…å«æ‰€æœ‰äººç‰©æ•¸æ“šçš„åˆ—è¡¨ã€‚
    -   **`person_id`**: äººç‰©çš„å”¯ä¸€IDï¼ˆç›®å‰ä¸»è¦è¿½è¹¤ID 0ï¼‰ã€‚
    -   **`keypoints`**: åŒ…å«è©²äººç‰©æ‰€æœ‰ç‰¹å¾µé»çš„ç‰©ä»¶ã€‚
        -   **`pose`**, **`left_hand`**, **`right_hand`**, **`face`**: å„éƒ¨ä½çš„ç‰¹å¾µé»åˆ—è¡¨ã€‚
            -   **`id`**: è©²éƒ¨ä½å…§ç‰¹å¾µé»çš„ç´¢å¼• (e.g., 0 for nose in pose)ã€‚
            -   **`x`, `y`**: åœ¨åŸå§‹å½±åƒç•«å¹…ä¸­çš„çµ•å°åƒç´ åº§æ¨™ã€‚
            -   **`confidence`**: è©²ç‰¹å¾µé»çš„ä¿¡è³´åˆ†æ•¸ã€‚

## ğŸŒ± æœªä¾†è¦åŠƒ (Roadmap)

-   [ ] **å¤šäººè¿½è¹¤ (Multi-Person Tracking)**: æ“´å……ç³»çµ±ä»¥åŒæ™‚è¿½è¹¤ä¸¦ç‚ºç•«é¢ä¸­çš„å¤šå€‹äººç”Ÿæˆå”¯ä¸€çš„IDå’ŒJSONæ•¸æ“šã€‚
-   [ ] **3D åº§æ¨™æ”¯æ´ (3D Coordinate Support)**: å°‡ MediaPipe æä¾›çš„ `z` åº§æ¨™æ•´åˆåˆ° JSON è¼¸å‡ºä¸­ï¼Œå¯¦ç¾å®Œæ•´çš„3Då§¿æ…‹æ•¸æ“šã€‚
-   [ ] **å³æ™‚è¾¨è­˜æ¨¡çµ„ (Real-Time Recognition Module)**: åŸºæ–¼è¼¸å‡ºçš„é—œéµé»åºåˆ—ï¼Œé–‹ç™¼ä¸€å€‹ç”¨æ–¼æ‰‹èªæˆ–å‹•ä½œè¾¨è­˜çš„å³æ™‚åˆ†é¡æ¨¡çµ„ã€‚
-   [ ] **æ•ˆèƒ½å„ªåŒ– (Performance Optimization)**: é‡å°ä¸åŒç¡¬é«”é€²è¡Œæ¨¡å‹æ¨è«–å„ªåŒ–ï¼Œä¾‹å¦‚ä½¿ç”¨ TensorRTã€‚
-   [ ] **Docker æ”¯æ´ (Dockerization)**: æä¾› Dockerfile ä»¥ç°¡åŒ–éƒ¨ç½²æµç¨‹ã€‚

## ğŸ¤ è²¢ç» (Contributing)

æ­¡è¿ä»»ä½•å½¢å¼çš„è²¢ç»ï¼ç„¡è«–æ˜¯å›å ±å•é¡Œ (Issues)ã€è«‹æ±‚æ–°åŠŸèƒ½ï¼Œé‚„æ˜¯æäº¤ç¨‹å¼ç¢¼åˆä½µè«‹æ±‚ (Pull Requests)ï¼Œéƒ½å°æœ¬å°ˆæ¡ˆæœ‰æ¥µå¤§å¹«åŠ©ã€‚

## ğŸ“„ æˆæ¬Š (License)

æœ¬å°ˆæ¡ˆæ¡ç”¨ [MIT License](LICENSE) æˆæ¬Šã€‚